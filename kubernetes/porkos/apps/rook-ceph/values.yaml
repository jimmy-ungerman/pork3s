operator:
  image:
    repository: ghcr.io/rook/ceph
    tag: v1.17.3
  csi:
    cephFSKernelMountOptions: ms_mode=prefer-crc
    # NOTE: Enable the driver and shapshotter if you want to use CephFS
    enableCephfsDriver: false
    enableCephfsSnapshotter: false
    enableLiveness: true
    serviceMonitor:
      enabled: true
  enableDiscoveryDaemon: true
  monitoring:
    enabled: true
  resources:
    requests:
      memory: 128Mi # unchangable
      cpu: 100m # unchangable
    limits: {}
    
rook-ceph-cluster:
  toolbox:
    enabled: true
  monitoring:
    enabled: true
    createPrometheusRules: true
  ingress:
    dashboard:
      ingressClassName: "nginx"
      host:
        name: "rook.porkboi.io"
        path: "/"
  cephClusterSpec:
    cephConfig:
      global:
        bdev_enable_discard: "true" # quote
        bdev_async_discard_threads: "1" # quote
        osd_class_update_on_start: "false" # quote
        device_failure_prediction_mode: local # requires mgr module
    network:
      provider: host
      connections:
        requireMsgr2: true
    crashCollector:
      disable: false
    csi:
      readAffinity:
        enabled: true
    dashboard:
      enabled: true
      urlPrefix: /
      ssl: false
      prometheusEndpoint: http://prometheus-operated.observability.svc.cluster.local:9090
    mgr:
      modules:
        - name: insights
          enabled: true
        - name: pg_autoscaler
          enabled: true
        - name: rook
          enabled: true    
        - name: diskprediction_local
          enabled: true
    storage:
      useAllNodes: true
      useAllDevices: false
      devicePathFilter: /dev/disk/by-id/nvme-Seagate_FireCuda_530_*
      config:
        osdsPerDevice: "1"
    resources:
      mgr:
        requests:
          cpu: "125m"
          memory: "512Mi"
        limits:
          memory: "1Gi"
      mon:
        requests:
          cpu: "50m"
          memory: "512Mi"
        limits:
          memory: "1Gi"
      osd:
        requests:
          cpu: "300m"
          memory: "512Mi"
        limits:
          memory: "6Gi"
      mgr-sidecar:
        requests:
          cpu: "50m"
          memory: "100Mi"
        limits:
          memory: "200Mi"
      crashcollector:
        requests:
          cpu: "15m"
          memory: "64Mi"
        limits:
          memory: "128Mi"
      logcollector:
        requests:
          cpu: "100m"
          memory: "100Mi"
        limits:
          memory: "1Gi"
      prepareosd:
        requests:
          cpu: "250m"
          memory: "50Mi"
        limits:
          memory: "2Gi"
      cleanup:
        requests:
          cpu: "250m"
          memory: "100Mi"
        limits:
          memory: "1Gi"
  cephBlockPoolsVolumeSnapshotClass:
    enabled: true
    name: csi-replicapool
    isDefault: false
    deletionPolicy: Delete
  cephBlockPools:
    - name: replicapool
      spec:
        failureDomain: host
        replicated:
          size: 3
      storageClass:
        enabled: true
        name: rook-ceph-block
        isDefault: true
        reclaimPolicy: Delete
        allowVolumeExpansion: true
        parameters:
          imageFormat: "2"
          imageFeatures: layering
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
          csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
          csi.storage.k8s.io/fstype: ext4
  cephFileSystems: []
  cephObjectStores: []